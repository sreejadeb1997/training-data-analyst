{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sreejadeb1997/training-data-analyst/blob/master/hw5_key_value_memory_network_assignment_v2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Preamble\n",
        "\n",
        "This mini-project involves working through all the steps of a problem, whereas prior assignments asked you to just implement core functions. We will give you a dataset, but you will also have the opportunity to manipulate the data in ways that you find beneficial to the overall project and to explain why and how those manipulations mattered. This will be in addition to building the model from scratch, developing the training loop, and implementing testing. The code will be accompanied by a report written into the notebook.\n",
        "\n",
        "This project will have you working with attention mechanism, in a new type of system for question-answering. This will provide you with experience working with attention mechanisms while not directly working with transformers.\n",
        "\n",
        "This assignment is not autograded. You can modify any code cells as long as you achieve the requirements of each graded component."
      ],
      "metadata": {
        "id": "3M1CFw-VT5vI"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yhZzhjGaTj9P"
      },
      "source": [
        "# Introduction\n",
        "\n",
        "Memory networks learn to access external memory stores (a database or, in the case of this assignment, a dictionary). Key-Value Memory Networks specifically assume that the external memory store is organized as a dictionary with keys and values. In theory memory networks are useful when one wants a neural network to be able to know a lot of information but we don't want to try to encode that information directly into the parameters of the network. This means information can be changed in the external memory database without retraining the neural network.\n",
        "\n",
        "Given a question, e.g., \"Where was Alexander Hamilton born?\", a key-value memory network learns an embedding such that the question has a high cosine similarity to a particular key in the external dictionary. Because there are many keys that need to be matched against, key-value memory networks implement an attention-scoring mechanism to select a key. Because attention is a probabilistic score, the key-value memory network retrieves a sum of embeddings weighted according to the attention score. This weighted embedding is then compared to values using a second attention-scoring mechanism. The value with the highest cosine similarity can then be retrieved and returned as the answer.\n",
        "\n",
        "Memory networks were an important part of the evolution of question-answering systems that have been eclipsed by transformers. However, the attention mechanism in a key-value memory network is very similar to the self-attention inside a transformer, so implementing a key-value memory network is a really great way to experiment and learn about self-attention without the added complexity of transformers.\n",
        "\n",
        "Key-value memory networks are also closely related to retieval-based generation networks, except we will be retrieving facts from a dictionary instead of via the internet. However, the embedding of retrieved data will be similar.\n",
        "\n",
        "Key-value memory networks are described in this [paper](https://arxiv.org/abs/1606.03126). It is recommended that you read the paper, but we will also walk through the steps you will need to complete."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XLQP14bxNXDx"
      },
      "source": [
        "# Some imports\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You may add imports as necessary."
      ],
      "metadata": {
        "id": "FAe6-NtARNjW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "JfnqkHKkITC3"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "import re\n",
        "import os\n",
        "import json\n",
        "import random\n",
        "import numpy as np\n",
        "import pickle\n",
        "from tqdm import tqdm\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "AviW7dfn6pUi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "0cf7f3ed-c162-4772-cd1c-2654180b8d7d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cpu'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "device"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Unidecode is useful for getting rid of issues that arise from unicode. This should not be used if we care about unicode, but for the purposes of an instructional exercise, it eliminates a lot of edge cases that come up with unicode."
      ],
      "metadata": {
        "id": "fQM96JBsVHwF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "EYuVdhWfAcGQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b89b8412-0511-4e5f-e5d7-ef38a0a5e86c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting unidecode\n",
            "  Downloading Unidecode-1.3.8-py3-none-any.whl.metadata (13 kB)\n",
            "Downloading Unidecode-1.3.8-py3-none-any.whl (235 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m235.5/235.5 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: unidecode\n",
            "Successfully installed unidecode-1.3.8\n"
          ]
        }
      ],
      "source": [
        "!pip install unidecode"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "3E_fVmV2_8ub"
      },
      "outputs": [],
      "source": [
        "import unidecode"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p_bDmt5iSD_j"
      },
      "source": [
        "If you need to have a reduced vocabulary, you can create an unknown \"unk\" token and add it to the vocabulary. Make sure the token index in the vocabulary and `UNK_ID` match."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "DDHhoxzyAByu"
      },
      "outputs": [],
      "source": [
        "UNK = 'unk'\n",
        "UNK_ID = '0'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sl6J8BwVpHCw"
      },
      "source": [
        "# Some utilities"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You may edit these as necessary."
      ],
      "metadata": {
        "id": "4LVVnmlNRKTp"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4KF3VeFoSenc"
      },
      "source": [
        "Stem words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "CPwG_8VrNUop"
      },
      "outputs": [],
      "source": [
        "# Stemming the text\n",
        "def simple_stemmer(text):\n",
        "    ps=nltk.porter.PorterStemmer()\n",
        "    text= [ps.stem(word) for word in text]\n",
        "    return text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mDg9vUiDShG-"
      },
      "source": [
        "Simple tokenizer that only keeps letters and numbers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "eEofSDrQ9fg_"
      },
      "outputs": [],
      "source": [
        "def tokenize(line):\n",
        "    line = re.sub(r'[^a-zA-Z0-9]', ' ', unidecode.unidecode(line)) # remove punctuation\n",
        "    line = line.lower().split()  # lower case\n",
        "    return line\n",
        "\n",
        "    #Tokenize string to convert to list of words, then give to stemming function"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IH2QW9FjSrJh"
      },
      "source": [
        "A standard vocabulary object class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "25siAXsXOJj9"
      },
      "outputs": [],
      "source": [
        "class Vocab:\n",
        "    def __init__(self, name = 'vocab'):\n",
        "        self.name = name\n",
        "        self._word2index = {}\n",
        "        self._word2count = {}\n",
        "        self._index2word = {}\n",
        "        self._n_words = 0\n",
        "\n",
        "    def get_words(self):\n",
        "      return list(self._word2count.keys())\n",
        "\n",
        "    def num_words(self):\n",
        "      return self._n_words\n",
        "\n",
        "    def word2index(self, word):\n",
        "      return self._word2index[word]\n",
        "\n",
        "    def index2word(self, word):\n",
        "      return self._index2word[word]\n",
        "\n",
        "    def word2count(self, word):\n",
        "      return self._word2count[word]\n",
        "\n",
        "    def add_sentence(self, sentence):\n",
        "        for word in tokenize(sentence):\n",
        "            self.add_word(word)\n",
        "\n",
        "    def add_word(self, word):\n",
        "        if word not in self._word2index:\n",
        "            self._word2index[word] = self._n_words\n",
        "            self._word2count[word] = 1\n",
        "            self._index2word[self._n_words] = word\n",
        "            self._n_words += 1\n",
        "        else:\n",
        "            self._word2count[word] += 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "esAT3lG1S5cV"
      },
      "source": [
        "Make a bag of words frmo a sentence, given a vocabulary. Can return a bag of word counts or a a bag of word presences."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "oKJP2y8g-TFE"
      },
      "outputs": [],
      "source": [
        "#revamped the multihot encoding function to return float instead of boolean T/F for encoding\n",
        "def multihot(s, vocab, preserve_counts = False):\n",
        "  tokens = np.array([vocab.word2index(t) for t in tokenize(s)])\n",
        "  mhot = np.zeros((tokens.size, vocab.num_words()))\n",
        "  mhot[np.arange(tokens.size), tokens] = 1\n",
        "  if preserve_counts:\n",
        "    return (mhot.sum(0)).astype(np.float32)\n",
        "    # return torch.tensor(mhot.sum(0))\n",
        "  else:\n",
        "    return (mhot.sum(0) >= 1).astype(np.float32)\n",
        "    # return torch.tensor(mhot.sum(0) >= 1)\n",
        "\n",
        "# mhot=multihot(\"alexander hamilton\", VOCAB)\n",
        "# print(mhot)\n",
        "# indices = np.nonzero(mhot == 1)\n",
        "# print(indices)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4w8BflMUTLW_"
      },
      "source": [
        "If you have a reduced vocabulary, use this to replace out-of-vocab words. If you use this, you may want to merge it with `multihot` above to avoid tokenizing twice."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "LfvAfjEl7Z6j"
      },
      "outputs": [],
      "source": [
        "def unkit(s, vocab):\n",
        "  return ' '.join(list(map(lambda x: UNK if x not in vocab._word2index else x, tokenize(s))))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YHZm-bAanrrf"
      },
      "source": [
        "# Part A: Download and Process Data (0 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u-L61V7tVPok"
      },
      "source": [
        "This dataset contains the information in tables that are commonly used in Wikipedia biography pages. Each person has different rows of information pertaining to their notable accomplishments and details about their life. There are a large number of types of information that can appear as rows in the biography tables, however they are relatively uniform. We call the keys of the rows \"relations\".\n",
        "\n",
        "For example [Alexander Hamilton](https://en.wikipedia.org/wiki/Alexander_Hamilton) has information about the President he worked for as Secretary of State, birth date, date of death, parents' names, etc.\n",
        "\n",
        "The code below will download the dataset and process it to create two things:\n",
        "- `DB`: a hash table that map titles of biography wikipedia articles to table information. The table information is represented as a nested hash table containing relations as keys, and associated values. For example, `DB['alexander hamilton'] = {'party': 'federalist',\n",
        " 'spouse': 'elizabeth schuyler', ...}`\n",
        "- `VOCAB`: A vocabulary object that maps words to tokens and vice versa."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PYzcdAR2ntvm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "15261e69-e0c6-4333-887b-dc8def5755d8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'wikipedia-biography-dataset'...\n",
            "remote: Enumerating objects: 93, done.\u001b[K\n",
            "remote: Total 93 (delta 0), reused 0 (delta 0), pack-reused 93 (from 1)\u001b[K\n",
            "Receiving objects: 100% (93/93), 338.68 MiB | 25.10 MiB/s, done.\n",
            "Resolving deltas: 100% (43/43), done.\n",
            "Updating files: 100% (19/19), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/rlebret/wikipedia-biography-dataset.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RZEHbtftn17L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "06c93168-e073-437d-d9e2-cc42fb3bbbd4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  tmp.zip\n",
            "   creating: wikipedia-biography-dataset/test/\n",
            "  inflating: wikipedia-biography-dataset/test/test.box  \n",
            "  inflating: wikipedia-biography-dataset/test/test.id  \n",
            "  inflating: wikipedia-biography-dataset/test/test.nb  \n",
            "  inflating: wikipedia-biography-dataset/test/test.sent  \n",
            "  inflating: wikipedia-biography-dataset/test/test.url  \n",
            "  inflating: wikipedia-biography-dataset/test/test.contributors  \n",
            "  inflating: wikipedia-biography-dataset/test/test.title  \n",
            "   creating: wikipedia-biography-dataset/train/\n",
            "  inflating: wikipedia-biography-dataset/train/train.box  \n",
            "  inflating: wikipedia-biography-dataset/train/train.id  \n",
            "  inflating: wikipedia-biography-dataset/train/train.nb  \n",
            "  inflating: wikipedia-biography-dataset/train/train.sent  \n",
            "  inflating: wikipedia-biography-dataset/train/train.url  \n",
            "  inflating: wikipedia-biography-dataset/train/train.contributors  \n",
            "  inflating: wikipedia-biography-dataset/train/train.title  \n",
            "   creating: wikipedia-biography-dataset/valid/\n",
            "  inflating: wikipedia-biography-dataset/valid/valid.box  \n",
            "  inflating: wikipedia-biography-dataset/valid/valid.id  \n",
            "  inflating: wikipedia-biography-dataset/valid/valid.nb  \n",
            "  inflating: wikipedia-biography-dataset/valid/valid.sent  \n",
            "  inflating: wikipedia-biography-dataset/valid/valid.url  \n",
            "  inflating: wikipedia-biography-dataset/valid/valid.contributors  \n",
            "  inflating: wikipedia-biography-dataset/valid/valid.title  \n",
            "  inflating: wikipedia-biography-dataset/LICENSE.txt  \n",
            "  inflating: wikipedia-biography-dataset/.DS_Store  \n",
            "  inflating: wikipedia-biography-dataset/._.DS_Store  \n",
            "  inflating: wikipedia-biography-dataset/README.txt  \n"
          ]
        }
      ],
      "source": [
        "!cat wikipedia-biography-dataset/wikipedia-biography-dataset.z?? > tmp.zip\n",
        "!unzip -o tmp.zip\n",
        "!rm tmp.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1rRYqmfSTcw0"
      },
      "source": [
        "Get all the wikipedia titles."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mdVrlCf-4TAq"
      },
      "outputs": [],
      "source": [
        "train_titles = []\n",
        "with open(\"wikipedia-biography-dataset/train/train.title\", \"r\") as file:\n",
        "  for line in file:\n",
        "    train_titles.append(line.rstrip())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YOkCic0NTeuS"
      },
      "source": [
        "Boxes contain all the information, with each line corresponding to a title in `titles`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C80pu63x4o-Y"
      },
      "outputs": [],
      "source": [
        "train_boxes = []\n",
        "with open(\"wikipedia-biography-dataset/train/train.box\", \"r\") as file:\n",
        "  for line in file:\n",
        "    train_boxes.append(line.rstrip())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "63cxS1DWTk0h"
      },
      "source": [
        "This will make the DB object, a dictionary of dictionaries for each wikipedia title, which is more or less the same as names. This function only keeps politicians (containing the \"office\" key term) and strips out information about images. It can be improved in many ways."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pr97KJLc4v7v"
      },
      "outputs": [],
      "source": [
        "# Make a dictionary of dictionaries\n",
        "def make_db(titles, boxes):\n",
        "  db = {} # The DB\n",
        "  # Iterate through titles\n",
        "  for i in tqdm(range(len(titles))):\n",
        "    box = boxes[i] # Grab the corresponding box information\n",
        "    d  = {} # Inner dictionary\n",
        "    # Build a dict for the ith entry\n",
        "    # grab each key:value pair\n",
        "    for pair in re.findall(r'([a-zA-Z_]+)[0-9]*\\:([\\w\\d]+)', box):\n",
        "      key, value = pair\n",
        "      # Do a bit of cleaning\n",
        "      key = key.strip()\n",
        "      value = value.strip()\n",
        "      # If the key contains the word image, we probably don't want to keep it\n",
        "      if 'image' not in key:\n",
        "        # The regex maintains underscores, strip those off\n",
        "        if key[-1] == '_':\n",
        "          key = key[:-1]\n",
        "        # Make a new entry in inner dictionary if we don't have one\n",
        "        if key not in d:\n",
        "          d[key] = value\n",
        "        # Keys with compound values are split up, which is annoying, so put them back together\n",
        "        else:\n",
        "          d[key] += ' ' + value\n",
        "    # If it has an office key, keep it.\n",
        "    if 'office' in d:\n",
        "      db[titles[i]] = d\n",
        "  return db"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S9hB1o63U45e"
      },
      "source": [
        "Build the vocab from the DB. Convert the whole thing into a string, tokenize it, and feed the surviving words into the vocab."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p13O5dcVvdZu"
      },
      "outputs": [],
      "source": [
        "def make_vocab(DB):\n",
        "  # Make the vocab object\n",
        "  vocab = Vocab()\n",
        "  # Tokenize the data by converting the entire DB into a string\n",
        "  tokens = tokenize(str(DB))\n",
        "  # Iterate through all the tokens (tqdm provides a progress bar)\n",
        "  for t in tqdm(tokens):\n",
        "    vocab.add_word(t)\n",
        "  return vocab"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zkjf7mbAVA9H"
      },
      "source": [
        "If you want to discard rare words, this will rebuild the vocab. This is just an example."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "448Ww-BFtBL3"
      },
      "outputs": [],
      "source": [
        "def reduce_vocab(vocab, min_word_occurrence = 2):\n",
        "  # make a new vocab\n",
        "  vocab2 = Vocab(\"top\")\n",
        "  # Add the UNK token\n",
        "  vocab2.add_word(UNK)\n",
        "  # Iterate through vocabulary\n",
        "  for w in list(vocab._word2count.keys()):\n",
        "    count = vocab._word2count[w]\n",
        "    idx = vocab._word2index[w]\n",
        "    # If the word count passes threshold, add it to the new vocabulary object\n",
        "    if count >= min_word_occurrence:\n",
        "      vocab2.add_word(w)\n",
        "      vocab2._word2count[w] = count\n",
        "  # Return the new vocabulary object\n",
        "  return vocab2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iVS602YPVE9N"
      },
      "source": [
        "Make the DB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cio_ZwncrGf0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "22d11c55-53ff-4044-d4dd-0950d1c5c6ee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 582659/582659 [00:36<00:00, 15829.38it/s]\n"
          ]
        }
      ],
      "source": [
        "DB = make_db(train_titles, train_boxes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ETLqtWtyVKLE"
      },
      "source": [
        "Make the VOCAB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lc7oi3p54SOb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ef524eae-d84f-45f2-aa30-3d0561f21485"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2997937/2997937 [00:01<00:00, 1831758.36it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "96093\n"
          ]
        }
      ],
      "source": [
        "VOCAB = make_vocab(DB)\n",
        "print(VOCAB.num_words())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y9AP3Dcle5VC"
      },
      "source": [
        "## Save Processed Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QiTQxguSXEuq"
      },
      "source": [
        "You may find it useful to save the processed dataset to your Google Drive.\n",
        "\n",
        "It is recommended that you save the file to your Google Drive. To mount your Google Drive, open the file icon on the left side of the screen to get to the option). To save the file in your Google Drive use the path `'drive/MyDrive/filename'`.)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "6DNxueU-gpz_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1daecc72-847f-4077-bc4b-3b1dfcdfede6"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DwagcDU_Ut2Q"
      },
      "outputs": [],
      "source": [
        "with open(\"drive/MyDrive/data\", \"wb\") as f:\n",
        "  pickle.dump(DB, f, protocol=None, fix_imports=True, buffer_callback=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WS6a8EtX_h0F"
      },
      "outputs": [],
      "source": [
        "with open('drive/MyDrive/vocab', 'wb') as f:\n",
        "    pickle.dump(VOCAB, f, protocol=None, fix_imports=True, buffer_callback=None)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lzlH6IKhe_Qa"
      },
      "source": [
        "## Load processed data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2AlkMbibXYWg"
      },
      "source": [
        "If you have saved the processed data in your Google Drive, you can re-load it with these commands."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "ZCaiBhdvCa_C"
      },
      "outputs": [],
      "source": [
        "with open(\"drive/MyDrive/vocab\", \"rb\") as f:\n",
        "  VOCAB = pickle.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "IinOyL_4C1Hx"
      },
      "outputs": [],
      "source": [
        "with open(\"drive/MyDrive/data\", \"rb\") as f:\n",
        "  DB = pickle.load(f)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vcZcFUxrfCnB"
      },
      "source": [
        "## Data example"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jKKoOuLCVYxd"
      },
      "source": [
        "Get to know your data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dbLkOyB2pp_M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a3659bc-69bf-4872-9c96-fb7227adc8bb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'name': 'alexander hamilton',\n",
              " 'office': '1st united states secretary of the treasury senior officer of the army delegate to the congress of the confederation from new york',\n",
              " 'president': 'george washington john adams',\n",
              " 'term_start': 'september 11 1789 december 14 1799 november 3 1788 november 4 1782',\n",
              " 'term_end': 'january 31 1795 june 15 1800 march 2 1789 june 21 1783',\n",
              " 'predecessor': 'position established george washington egbert benson seat established',\n",
              " 'successor': 'oliver wolcott jr james wilkinson seat abolished seat abolished',\n",
              " 'birth_date': '11 january 1755',\n",
              " 'birth_place': 'charlestown nevis british west indies',\n",
              " 'death_date': 'july 12 1804 aged 47 or 49',\n",
              " 'death_place': 'new york city new york u',\n",
              " 'party': 'federalist',\n",
              " 'spouse': 'elizabeth schuyler',\n",
              " 'children': 'philip angelica alexander james alexander john church william stephen eliza holly phil',\n",
              " 'alma_mater': 'kings college new york',\n",
              " 'religion': 'presbyterian episcopalian convert',\n",
              " 'signature': 'alexander hamilton signaturert',\n",
              " 'allegiance': 'flag_of_new_york _ 1778 svg 23px new york 1775 1777 united states 1795 23px 1777 1800',\n",
              " 'branch': 'flag_of_new_york _ 1778 svg 23px new york company of artillery united states 1777 23px continental army 25px united states army',\n",
              " 'serviceyears': '1775 1776 militia 1776 1781 1798 1800',\n",
              " 'rank': '23px',\n",
              " 'article_title': 'alexander hamilton'}"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "DB[\"alexander hamilton\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ITACHJTWfE5m"
      },
      "source": [
        "# Part B: Implement the Key-Value Memory Network (10 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xQqLE-fcI_43"
      },
      "source": [
        "This [paper](https://arxiv.org/abs/1606.03126) describes the key-value memory networks in detail, which is also sketched out below.\n",
        "\n",
        "A key-value memory network takes a natural language question. This question will be converted into a bag-of-words (i.e., a multihot) Call this $x$ and it is a 1D tensor of vocabulary length.\n",
        "\n",
        "![KVMemNet architecture](https://github.com/markriedl/kvmemnet-assignment/blob/32479dd1e88a9f8dfc72f11ccb8e9e0e1f78905f/kvmemnet-inside.png?raw=true)\n",
        "\n",
        "The KVMemNet will contain a linear layer (or embedding layer) that will produce a 1D embedding of the question $q=A(x)$.\n",
        "\n",
        "The KVMemNet will also take in a stack of keys as a tensor of shape `num_keys x vocab_size`. Each row is embedded using the same embedding, $k=A(keys)$, producing a tensor of shape `num_keys x embed_dim`. How this stack of keys is chosen will be discussed below.\n",
        "\n",
        "The KVMemNet will take in a third input, a stack of values associated with the stack of keys. This will also be of shape `num_values x vocab_size`. Each row is embedded using the same embedding, $v=A(values)$, producing a tensor of shape `num_keys x embed_dim`.\n",
        "\n",
        "The KVMemNet will also contain a second linear embedding layer, $B$. More on this later.\n",
        "\n",
        "Once we have `q`, `k`, and `v` embeddings, the next step is to use `q` and `k` to compute attention scores that can be applied against `v`. Think of $A$ as learning how to make questions and the keys that should match against values that have received the same treatment.\n",
        "\n",
        "The attention scores `p` are computed by taking the inner-product (`torch.inner()`) between `q` and `k`. The result will be a 1D tensor with `num_keys` length. Use softmax so that `p` contains scores between 1.0 and 0.0.\n",
        "\n",
        "You may be wondering why there isn't a non-linearity such as a sigmoid or ReLU after the linear layer. Softmax is a non-linearity.\n",
        "\n",
        "Next apply the `p` attention scores against `v` to apply a weight against each value in the stack of values. One should be highly weighted and the rest less weighted. Sum all the weighted values up to create a 1D tensor `o` of feature weights of length `embed_dim`. `p` can be thought of as how much of each value gets selected. Then they all get combined together and the feature weights are proportional to how much each value was attended to. The `torch.matmul()` can do the multiplication and summing in one step.\n",
        "\n",
        "The KVMemNet forward function should return this tensor of feature weights `o`.\n",
        "\n",
        "A quick note on `k` and `v`. We can't send the entire set of keys and values in our database through the network's forward function. Instead there should be a selection mechanism that selects just a subset of the database. This subset should contain the best key for the question $x$ to match against, and its corresponding value. We assume that a shallow selection process can narrow down the key-value pairs to a relatively small set, one of which will be best. For example, if the question involves \"Alexander Hamilton\", we can reasonably guess that the best key-value pair is in the part of the database associated with the named person.\n",
        "\n",
        "We are not done though. What about our linear layer $B$? Suppose variable `Y` contains our entire set of values in our databse as bags of words. $B$ is going to be used to embed our entire set of database values $y=B(Y)$. $B$ can be thought of as learning how to make all the values look like the feature weights output by the model such that the highest cosine similarity corresponds to the correct value taken from *all* values in the database.\n",
        "\n",
        "$B$ should live inside the KVMemNet object so that its parameters become trainable, but notice that we do not use $B$ in the KVMemNet's forward function. $B$ will get used to prepare the stack of all values in the database for training. It will bet used in the training loop but outside of the forward function. This is a bit unusual, but necessary to figure out the correct target (the true index of the best value to match against) for training.\n",
        "\n",
        "The above explantion only implements *single-hop* retrieval. *multi-hop* retrieval allows the results of one retrieval to inform a second (and third and so on) to get the right retrieval. This would be used in the case where the answer cannot be inferred directly from the question in a single retrieval, such as \"What was the founding date of the country that Alexander Hamilton was born in?\". To implement multi-hop retrieval, the KVMemNet will have additional linear layers $R_1...R_n$. Each $R_{i}$ will do a linear transform on `q` then attention will score and retrieve values as feature weights `o`. This will be sent to the next $R_{i+1}$ and so on until the hops are complete. This final `o` will be returned.\n",
        "\n",
        "For this assignment is is sufficient to only do *single-hop* retrieval.\n",
        "\n",
        "The above explanation does not include consideration of batching. You may want to add a batch dimension as the first dimension and input a batch as a set of questions, a set of stacks of keys, and a set of stacks of values. To do this, functions like `.inner()`, `.mm()`, and`.matmul()` will not work. Instead use `.bmm()` which handles batching correctly. You will probably need to do some `.squeeze()` and `.unsqueeze()` operations to make sure your tensors are the correct shapes.\n",
        "\n",
        "Instead of bag-of-words, one may also consider first converting each question, key, and value into a general set of embeddings such as [GLoVe](https://nlp.stanford.edu/projects/glove/). To do this one will need to consider how to combine words--convert each word into an embedding vector and then add the vectors together (or maybe average them)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DSf1SSX7bgdE"
      },
      "source": [
        "**Complete the key-value memory net code**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "9zex3XZzw0-l"
      },
      "outputs": [],
      "source": [
        "class KVMemNet(nn.Module):\n",
        "  def __init__(self, vocab_size, embed_dim):\n",
        "    super(KVMemNet, self).__init__()\n",
        "    self.vocab_size = vocab_size\n",
        "    self.embed_dim = embed_dim\n",
        "    ### YOUR CODE HERE\n",
        "\n",
        "    ''' Citation: HW5 recitation\n",
        "    #batching done in KVMemNet - check if the training can also be done in batches to reduce time?\n",
        "\n",
        "    '''\n",
        "\n",
        "    self.A=nn.Linear(vocab_size, embed_dim)\n",
        "    self.B=nn.Linear(vocab_size, embed_dim)\n",
        "    self.softmax=nn.Softmax(dim=1)\n",
        "\n",
        "  def forward(self, x, keys, values):\n",
        "    output = None\n",
        "    ### YOUR CODE BELOW\n",
        "    '''\n",
        "    Steps to be done:\n",
        "\n",
        "    x=[batch_size, vocab_size]--> q=[batch_size, embed_dim]\n",
        "    k=[batch_size, num_keys, vocab_size]--> [batch_size, num_keys, embed_dim]\n",
        "    v=[batch_size, num_keys, vocab_size]--> [batch_size, num_keys, embed_dim]\n",
        "\n",
        "    p=softmax(q.k) --> [batch_size, num_keys]\n",
        "    output=p.v --> [batch_size, embed_dim]\n",
        "    '''\n",
        "\n",
        "    batch_size=x.shape[0]\n",
        "    num_keys=keys.shape[1]\n",
        "\n",
        "    q=self.A(x) #[batch_size, embed_dim]\n",
        "    k=self.A(keys) #[batch_size, num_keys, embed_dim]\n",
        "    v=self.A(values) #[batch_size, num_keys, embed_dim]\n",
        "\n",
        "    q=q.unsqueeze(1)  #[batch_size, 1, embed_dim]\n",
        "    p=torch.bmm(q, k.transpose(1, 2)).squeeze(1)  #[batch_size, 1, embed_dim] bmm [batch_size, embed_dim, num_keys] = [batch_size, 1, num_keys] --> squeeze at 1 = [batch_size, num_keys]\n",
        "    p=self.softmax(p)\n",
        "\n",
        "\n",
        "    p=p.unsqueeze(1)  #[batch_size, 1, num_keys]\n",
        "    output=torch.bmm(p, v).squeeze(1)  #[batch_size, 1, num_keys] bmm [batch_size, num_keys, embed_dim] = [batch_size, 1, embed_dim] --> squeeze at 1 = [batch_size, embed_dim]\n",
        "\n",
        "    ### YOUR CODE ABOVE\n",
        "    return output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p8pshjz9hRps"
      },
      "source": [
        "\n",
        "# Synthetic Data Set\n",
        "\n",
        "This is a synthetic dataset. One way to test a model during development is to take a small piece of data and show that you can overfit a model. If you can't overfit an easily learned chunk of data, then you probably have something wrong in your code. In this case I have provided a small chunk of synthetic data that should be easy to learn.\n",
        "\n",
        "- The vocabulary is 20 word: 5 names, 5 relations, 5 question-words, 5 values\n",
        " - First 5 elements of the vocab are names (for example index 0 might be \"Hamilton\").\n",
        " - Second 5 elements of the vocab are relations (for example, \"born\", \"died\", \"occupation\").\n",
        " - Third 5 elements are random words that might be part of a query (for example, \"When was\").\n",
        " - Final 5 elements of the vocab are possible values (for example, \"1757\")\n",
        "- A \"question\" is a name (5, 1), relation (5, 1), some words (5, 1), and no values\n",
        "- The keys will all have the same name (5, 5) where each row is idential, relations (5, 5), no words, no values\n",
        "- Values will have no names, no relations, no words, and value vocab words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qvuyp-g7grYw"
      },
      "outputs": [],
      "source": [
        "# Turn on a different relation on each row\n",
        "relations = torch.zeros(5, 5)\n",
        "relations.fill_diagonal_(1)\n",
        "\n",
        "# training data\n",
        "train_data = {}\n",
        "for i in range(5):\n",
        "  # Name associated with questions, keys, values\n",
        "  '''\n",
        "  Understanding the structure of synthetic data to be reconstructed for train-test:\n",
        "\n",
        "  train_data[0] for the same person Hamilton(repeated 5 times), 5 relation, 5 question-words, 5 values corresponding\n",
        "\n",
        "            questions [5,20] - stacks name, relation, words, values horizontally --> \"Hamilton (1X5) Born(1X5) When(1X5) zero(1X5)\" 5 such rows for 5 different questions regarding hamilton\n",
        "              name (5, 5) -> Name\n",
        "              relation (5, 5) -> Relations\n",
        "              words (5, 5) -> Random question words\n",
        "              values (5, 5) -> No values\n",
        "\n",
        "            keys [5,20] --> \"Hamilton (1X5) Born(1X5) zero(1X5) zero(1X5)\" 5 such rows\n",
        "              name (5, 5) -> Name\n",
        "              relation (5, 5) -> Relations\n",
        "              words (5, 5) -> No question words\n",
        "              values (5, 5) -> No values\n",
        "\n",
        "            values [5,20] --> \"zero (1X5) zero(1X5) zero(1X5) 1755(1X5)\" 5 such rows\n",
        "              name (5, 5) -> No Name\n",
        "              relation (5, 5) -> No Relations\n",
        "              words (5, 5) -> No  question words\n",
        "              values (5, 5) -> values\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  Y --> \"zero (1X5) zero(1X5) zero(1X5) 1755(1X5)\" 5 such rows for 5 different values from train[0] Hamilton, 5 such for all train\n",
        "          extracts the 'values' tensor ((5, 20)) from each train_data[i]\n",
        "          Stacks all 5 (5 training points) vertically\n",
        "          [5* 5, 20] --> [25, 20]\n",
        "  '''\n",
        "  train_data[i] = (torch.cat([F.one_hot(torch.arange(0, 5))[i].repeat(5, 1),\n",
        "                         relations,\n",
        "                         torch.randint(0, 2, (5, 5)).float(),\n",
        "                         torch.zeros(5, 5)], dim=1),\n",
        "              torch.cat([F.one_hot(torch.arange(0, 5))[i].repeat(5, 1),\n",
        "                         relations,\n",
        "                         torch.zeros(5, 5),\n",
        "                         torch.zeros(5, 5)], dim=1),\n",
        "              torch.cat([torch.zeros(5, 5),\n",
        "                         torch.zeros(5, 5),\n",
        "                         torch.zeros(5, 5),\n",
        "                         torch.randint(0, 2, (5, 5)).float()], dim=1))\n",
        "  Y = torch.cat([v[2] for v in list(train_data.values())], dim=0)#.to('cuda')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G6R_xIi_TZVp"
      },
      "source": [
        "# Part C: Train on Synthetic Data (5 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4slHUG5cPDtT"
      },
      "source": [
        "The following describes the steps to set up a training loop, including the training of the $B$ layer.\n",
        "\n",
        "![The KVMemNet being used in the training loop](https://github.com/markriedl/kvmemnet-assignment/blob/main/kvmemnet-outside.png?raw=true)\n",
        "\n",
        "- Create a model with the given vocabulary size and an embedding size that is equal to or smaller.\n",
        "- Loop through `N` epochs:\n",
        " - There are five names, loop through each name.\n",
        "   - Get a stack of questions, stack of keys, and stack of values from `DB_synth`.\n",
        "   - Loop through the relations. There is relation on each row of the keys and values.\n",
        "     - Get a single question, the `i`-th row in the questions pulled from `DB_synth` above.\n",
        "     - Compute the target: this is the `name*5 + i` element in `Y`.\n",
        "     - Run the singular question, stack of keys, and stack of values through the model and produce an output, which is a tensor of feature weights.\n",
        "     - Run all of `Y` through `model.B()` to get an embedded stack of values.\n",
        "     - Take the softmax of the inner product between the embedded stack of values from `Y` and the feature weight generated by the model.\n",
        "     - Compute the loss with `nn.CrossEntropyLoss`.\n",
        "     - Call `.backward()` on the loss.\n",
        "\n",
        "In addition to printing the loss (after every question or after every name in `DB_synth`) you can also print the target and the argmax of the softmax result to see if they match. Over time you should see the target and the argmax in agreement. For the purposes of this part of the project it is sufficient to test on the training set.\n",
        "\n",
        "Don't forget to move the model and the tensor to the GPU.\n",
        "\n",
        "You may want to speed up training by implementing batching. To do this, the model `forward()` needs to take tensors with an extra batching dimension as the first dimension. However, `.inner()`, `.mm()`, and `.matmul()` will not work properly. You will need to use `.bmm()` instead, which understands the first dimension is for batching. You will likely find that you need to perform some `.squeeze()` and `.unsqueeze()` operations. You can try batch-size of one, or take entire chunks (or even all synthetic data as a single, large batch). Try it different ways.\n",
        "\n",
        "Try training on the synthetic data first."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You may make as many cells as necessary. Save your notebook outputs that plot loss and show it reducing."
      ],
      "metadata": {
        "id": "zu1CMkabZkyU"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0MqIdFVAbqr1"
      },
      "source": [
        "**Write code blocks below that create the `KVMemNet`**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up your KVMemNet, move it to the GPU, setup up optimizer (e.g., Adam), and criterion.\n",
        "vocab_size=20\n",
        "embed_dim=10\n",
        "model=KVMemNet(vocab_size, embed_dim)#.to('cuda')  #move it to the GPU\n",
        "\n",
        "optimizer=optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "criterion=nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "wxso4hXaTKSK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "001D35pTb82K"
      },
      "source": [
        "**Write and run a training testing loop. Show that your training loop loss converges with a plot**\n",
        "\n",
        "To plot a loss curve, compute the mean loss per epoch and save it in a list:\n",
        "```\n",
        "x_axis.append(epoch_number)\n",
        "y_axis.append(mean_epoch_loss_for_this_epoch)\n",
        "plt.plot(x_axis, y_axis)\n",
        "plt.show()\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "'''\n",
        "Citation: HW5 recitation\n",
        "\n",
        "Steps of training:\n",
        "- Each batch is 5 rows (5 key-value pairs).\n",
        "- Each of the 5 questions map to the corresponding key(relation) and values(answers) attributed to that person (repeated 5 times)\n",
        "- Run the singular question, stack of keys, and stack of values through the model to get the output weights.\n",
        "- Map these weights to the embedded stack of values from Y to get the corresponding Y (predicted target)\n",
        "- Get the target from stacked values of Y (actual target)\n",
        "\n",
        "Results:\n",
        "- Get the CE loss and map loss curve over epochs to see if the loss is reducing\n",
        "- Also see if the targets and predicted match over epochs.\n",
        "As the synthetic data is very small so overtraining should happen but still some randomness in terms of data synthesized so the Y stacked values might have duplicate values\n",
        "i.e two values in Y (all values in database) might be the same so the weighted output might map to either of them\n",
        "\n",
        "\n",
        "'''\n",
        "\n",
        "epochs = 500 #100\n",
        "batch_size = 1  # Using batch size of 1 for this example\n",
        "train_losses = []  # for plotting\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    epoch_loss = 0.0\n",
        "\n",
        "    # Loop over batches (each batch is a slice of 5 rows for this example)\n",
        "    for name_index in range(5):\n",
        "        questions, keys, values = train_data[name_index]\n",
        "        keys=keys#.to('cuda')\n",
        "        values=values#.to('cuda')\n",
        "\n",
        "        for relation_index in range(5):\n",
        "          question=questions[relation_index]#.to('cuda')\n",
        "          # print(\"q,k,v sizes:\" ,question.size(), keys.size(), values.size())\n",
        "          output = model(question.unsqueeze(0), keys.unsqueeze(0), values.unsqueeze(0))\n",
        "          output=output.squeeze(0)\n",
        "          # print(\"output: \",output.size())\n",
        "\n",
        "          # print(\"Y: \", Y.size())\n",
        "          embedded_Y = model.B(Y)\n",
        "          # print(\"embedded_Y: \", embedded_values.size())\n",
        "\n",
        "          softmax_output = torch.inner(embedded_Y, output)\n",
        "          # print(\"softmax_output: \",softmax_output.size())\n",
        "\n",
        "          target_index=torch.tensor(name_index*5+relation_index)#.to('cuda')\n",
        "          # print(\"target_index: \",target_index.size())\n",
        "\n",
        "\n",
        "          # Accumulate loss\n",
        "          loss = criterion(softmax_output, target_index)\n",
        "          epoch_loss += loss.item()\n",
        "\n",
        "          # Backward pass\n",
        "          optimizer.zero_grad()\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "\n",
        "\n",
        "          # Predicted class as the highest prob in output\n",
        "          predicted = softmax_output.argmax(dim=0)\n",
        "\n",
        "          if (epoch + 1) % 100 == 0 and name_index==4:  # Print loss every 100 epochs and last name just to reduce verbose print\n",
        "              # print(f\"Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.4f}\")\n",
        "              print(f\"Target: \",target_index.item())\n",
        "              print(f\"Predicted: {predicted}\")\n",
        "\n",
        "    avg_loss = epoch_loss / (5 * 5)  # Normalize by total iterations\n",
        "    train_losses.append(avg_loss)\n",
        "\n",
        "    if (epoch + 1) % 100 == 0:  # Print loss every 50 epochs\n",
        "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {avg_loss:.4f}\")\n",
        "\n",
        "# Plot loss over epochs\n",
        "plt.plot(range(1, epochs + 1), train_losses, label=\"Training Loss\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.title(\"Training Loss Curve\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "rImsQ2M7hDo-",
        "outputId": "8855630b-7d5b-436f-c7da-fe9d45dcabf9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Target:  20\n",
            "Predicted: 10\n",
            "Target:  21\n",
            "Predicted: 3\n",
            "Target:  22\n",
            "Predicted: 2\n",
            "Target:  23\n",
            "Predicted: 23\n",
            "Target:  24\n",
            "Predicted: 24\n",
            "Epoch 100/500, Loss: 1.1655\n",
            "Target:  20\n",
            "Predicted: 10\n",
            "Target:  21\n",
            "Predicted: 21\n",
            "Target:  22\n",
            "Predicted: 2\n",
            "Target:  23\n",
            "Predicted: 23\n",
            "Target:  24\n",
            "Predicted: 12\n",
            "Epoch 200/500, Loss: 0.7903\n",
            "Target:  20\n",
            "Predicted: 10\n",
            "Target:  21\n",
            "Predicted: 21\n",
            "Target:  22\n",
            "Predicted: 2\n",
            "Target:  23\n",
            "Predicted: 23\n",
            "Target:  24\n",
            "Predicted: 24\n",
            "Epoch 300/500, Loss: 0.7571\n",
            "Target:  20\n",
            "Predicted: 10\n",
            "Target:  21\n",
            "Predicted: 21\n",
            "Target:  22\n",
            "Predicted: 2\n",
            "Target:  23\n",
            "Predicted: 23\n",
            "Target:  24\n",
            "Predicted: 12\n",
            "Epoch 400/500, Loss: 0.7510\n",
            "Target:  20\n",
            "Predicted: 10\n",
            "Target:  21\n",
            "Predicted: 21\n",
            "Target:  22\n",
            "Predicted: 2\n",
            "Target:  23\n",
            "Predicted: 23\n",
            "Target:  24\n",
            "Predicted: 12\n",
            "Epoch 500/500, Loss: 0.7496\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nupd-Gr9P6vc"
      },
      "source": [
        "# Part D: Training on the Full Data (10 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r02Y9yvhPXy8"
      },
      "source": [
        "To train on the full data, you are going to need to do some pre-processing of the data.\n",
        "\n",
        "First, there are no \"questions\". You need to generate questions for each type of relation. There a number of ways to do this. The simplest is to just assume that a question is the name of a person and a relation, e.g., \"Alexander Hamilton birth date\". Another way would be to create templates for each type of relation. For example the \"birth date\" relation would have the following template: \"When was [name] born?\", filling in the [name]. Because there are a lot of different types of relations, you may want to remove the more obscure relations so you need fewer templates and also have a smaller vocabulary. Templates work well if the questions are expected to be almost identical to the templates. You may want to generate multiple templates per relation. Continuing the previous example, a second template would be: \"What is the birthdate of [name]?\".\n",
        "\n",
        "If you are feeling more ambitious, you could use GPT-J, GPT-NeoX, GPT-3 or ChatGPT to generate templates. It works decently well and you can get some variety of templates.\n",
        "\n",
        "The question should contain information about the person and some words that are representative of the relation even if the exact relation words aren't used (the KVMemNet should figure out that \"birthdate\" and \"born\" are correlated).\n",
        "\n",
        "You only put a subset of all key-value pairs into the KVMemNet. You need a technique for sub-selecting from all the key-value pairs in `DB`. You might just need the ones that are directly associated with the person (Alexander Hamilton has 23). You may need to mix in a few key-value pairs from another person's entries in the database to help ensure against accidental overfitting.\n",
        "\n",
        "The final challenge you will have in the training loop is that there may still be too many unique values in `Y` to encode and create one big tensor. In that case, you can at least use the values that you sent to the KVMemNet, along with as many other randomly selected values as you can fit into the GPU's memory."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3I3CTqeEfa1m"
      },
      "source": [
        "Create as many cells below as you need. Save the output of your training and testing functions, reporting loss during training and accuracy during testing. 5 points for a training loop that reduces loss. 5 points for a training function with a correct accuracy computation."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Create a training dataset and a non-overlapping testing dataset**\n",
        "\n",
        "If CPU memory becomes a problem you might want to consider a `DataLoader` so that data can be stored on file and pulled up when needed."
      ],
      "metadata": {
        "id": "D-970kRwZ26n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create your training and test sets here"
      ],
      "metadata": {
        "id": "V6VEnB_VS7Px"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Citation: HW5 recitation\n",
        "\n",
        "Each train row is for a dedicated person and number of rows within the person-set is the number of relations.\n",
        "For training purpose I am limiting to the birth date, birth place, death date, death place, office relation only.\n",
        "The (q,k,v) set for each relation of the person is set as below-\n",
        "  q= name\n",
        "  k= name key\n",
        "  v= name value\n",
        "\n",
        "I am working with CPU hence just training with 100 person records. Testing over 10 persons.\n",
        "\n",
        "'''\n",
        "\n",
        "d=[]\n",
        "for name, content in DB.items():\n",
        "  # print(name,content)\n",
        "  person=[]\n",
        "  for key, value in content.items():\n",
        "    if \"birth\" in key or \"death\" in key or \"office\" in key:\n",
        "      # print(name, \"-\" , key, \"-\" , value)\n",
        "      tmp = [name, \"{} {}\".format(name, key), \"{} {}\".format(name, value)]\n",
        "      person.append(tmp)\n",
        "  d.append(person)\n",
        "\n",
        "train_num=100\n",
        "test_num=train_num+10\n",
        "train_data=d[:train_num]\n",
        "test_data=d[train_num:test_num]\n",
        "\n",
        "train_data[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KE4kMzr2v3L4",
        "outputId": "dfe6ff44-c3ee-40a6-e0de-891e0ea2e892"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['j. p. featherston',\n",
              "  'j. p. featherston birth_date',\n",
              "  'j. p. featherston november 28 1830'],\n",
              " ['j. p. featherston',\n",
              "  'j. p. featherston birth_place',\n",
              "  'j. p. featherston durham county durham'],\n",
              " ['j. p. featherston',\n",
              "  'j. p. featherston death_date',\n",
              "  'j. p. featherston 1917'],\n",
              " ['j. p. featherston',\n",
              "  'j. p. featherston death_place',\n",
              "  'j. p. featherston ottawa'],\n",
              " ['j. p. featherston',\n",
              "  'j. p. featherston office',\n",
              "  'j. p. featherston mayor of ottawa']]"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MI3b5x2zfl8g"
      },
      "source": [
        "**Create your `KVMemNet`**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up your KVMemNet here\n",
        "vocab_size=VOCAB.num_words()\n",
        "embed_dim=100 #Setting a larger embedding size than synthetic data because the vocab size is huge here, so while squeezing all info from vocabsize to the embedding size less info loss would be faced.\n",
        "model=KVMemNet(vocab_size, embed_dim)#.to('cuda')  #move it to the GPU\n",
        "\n",
        "optimizer=optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "criterion=nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "OEKJ1KJxTBUJ"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Ug_8X-2fwYD"
      },
      "source": [
        "**Write and run a training loop, showing a loss plot**\n",
        "\n",
        "You may find it handy to also test your network on the test data periodically as it trains."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Training loop goes here\n",
        "\n",
        "\n",
        "'''\n",
        "Citation: HW5 recitation\n",
        "\n",
        "Each train row is for a dedicated person and number of rows within the person-set is the number of relations.\n",
        "For training purpose I am limiting to the birth date, birth place, death date, death place, office relation only.\n",
        "The (q,k,v) set for each relation of the person is set as below-\n",
        "  q= name\n",
        "  k= name key\n",
        "  v= name value\n",
        "\n",
        "For getting Y- The recitation showed we are attempting to figure out in the person specific BOW only rather than all the values in the database (which would help with computation resources availability)\n",
        "\n",
        "'''\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "\n",
        "epochs = 10 #500 #100\n",
        "train_losses = []  # for plotting\n",
        "\n",
        "# #Creating the entire BOW of values for Y from all values in the database. But the recitation showed we are attempting to figure out in the person specific BOW only (which would help with computation resources availability) thus used B(value for that person) and not B(Y_encoded)\n",
        "# Y = [row[2] for row in train_data[0]] #torch.cat([v[2] for v in list(train_data.values())], dim=0)#.to('cuda')\n",
        "# Y_encoded=[multihot(row, VOCAB) for row in Y]\n",
        "# Y_encoded=torch.tensor(Y_encoded)#.to('cuda')\n",
        "# Y_encoded.size()\n",
        "\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    epoch_loss = 0.0\n",
        "\n",
        "    # Loop over batches (each batch is a slice of 5 rows - birtdate, birthplace,deatdate, deathplace, office)\n",
        "    for name_index in range(train_num):\n",
        "        # print(\"name_index: \", name_index)\n",
        "        batch_data = train_data[name_index]\n",
        "        # print(\"batch_data shape: \", batch_data)\n",
        "        keys=[multihot(row[1], VOCAB) for row in batch_data]\n",
        "        values=[multihot(row[2], VOCAB) for row in batch_data]\n",
        "        keys=torch.tensor(keys)#.to('cuda')\n",
        "        values=torch.tensor(values)#.to('cuda')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        for relation_index in range(len(batch_data)): #5 relations - birtdate, birthplace,deatdate, deathplace, office\n",
        "          question=keys[relation_index].clone()#.to('cuda')\n",
        "\n",
        "          # print(\"q,k,v sizes:\" ,question.size(), keys.size(), values.size())\n",
        "          output = model(question.unsqueeze(0), keys.unsqueeze(0), values.unsqueeze(0))\n",
        "          output=output.squeeze(0)\n",
        "          # print(\"output: \",output.size())\n",
        "\n",
        "          # print(\"Y: \", Y.size())\n",
        "          embedded_Y = model.B(values.clone())\n",
        "          # embedded_Y = model.B(Y_encoded)\n",
        "          # print(\"embedded_Y: \", embedded_values.size())\n",
        "\n",
        "          softmax_output = torch.inner(embedded_Y, output)\n",
        "          # print(\"softmax_output: \",softmax_output.size())\n",
        "\n",
        "          target_index=torch.tensor(relation_index)#.to('cuda')\n",
        "          # print(\"target_index: \",target_index.size())\n",
        "\n",
        "\n",
        "          # Accumulate loss\n",
        "          loss = criterion(softmax_output, target_index)\n",
        "          epoch_loss += loss.item()\n",
        "\n",
        "          # Backward pass\n",
        "          optimizer.zero_grad()\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "\n",
        "\n",
        "          # Predicted class as the highest prob in output\n",
        "          predicted = softmax_output.argmax(dim=0)\n",
        "\n",
        "          # if (epoch + 1) % 100 == 0 and name_index==4:  # Print loss every 100 epochs and last name just to reduce verbose print\n",
        "          #     # print(f\"Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.4f}\")\n",
        "          #     print(f\"Target: \",target_index.item())\n",
        "          #     print(f\"Predicted: {predicted}\")\n",
        "\n",
        "          # print(f\"Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.4f}\")\n",
        "          # print(f\"Target: \",target_index.item())\n",
        "          # print(f\"Predicted: {predicted}\")\n",
        "\n",
        "    avg_loss = epoch_loss / (5 * train_num)  # Normalize by total iterations = train_num * 5 relations (born-2, death-2, office-1)\n",
        "    train_losses.append(avg_loss)\n",
        "\n",
        "    # if (epoch + 1) % 100 == 0:  # Print loss every 50 epochs\n",
        "    print(f\"Epoch {epoch+1}/{epochs}, Loss: {avg_loss:.4f}\")\n",
        "\n",
        "# Plot loss over epochs\n",
        "plt.plot(range(1, epochs + 1), train_losses, label=\"Training Loss\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.title(\"Training Loss Curve\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "-K6rxBHFTEPO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        },
        "outputId": "68f4a3cf-84c2-49e9-b51d-e9e4ca0f39b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10, Loss: 0.9753\n",
            "Epoch 2/10, Loss: 0.7087\n",
            "Epoch 3/10, Loss: 0.6196\n",
            "Epoch 4/10, Loss: 0.5639\n",
            "Epoch 5/10, Loss: 0.4568\n",
            "Epoch 6/10, Loss: 0.3491\n",
            "Epoch 7/10, Loss: 0.2857\n",
            "Epoch 8/10, Loss: 0.2324\n",
            "Epoch 9/10, Loss: 0.1725\n",
            "Epoch 10/10, Loss: 0.1253\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7g5uXKRAgDjD"
      },
      "source": [
        "**Write the code for testing your model on the test data**\n",
        "\n",
        "Your training loop can call the testing loop. But make sure that you do one last test on the model after training completes."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing loop goes here\n",
        "correct=0\n",
        "total=0\n",
        "\n",
        "# Loop over batches (each batch is a slice of 5 rows - birtdate, birthplace,deatdate, deathplace, office\n",
        "for name_index in range(10):\n",
        "    # print(\"name_index: \", name_index)\n",
        "    batch_data = test_data[name_index]\n",
        "    # print(\"batch_data shape: \", batch_data)\n",
        "    keys=[multihot(row[1], VOCAB) for row in batch_data]\n",
        "    values=[multihot(row[2], VOCAB) for row in batch_data]\n",
        "    keys=torch.tensor(keys)#.to('cuda')\n",
        "    values=torch.tensor(values)#.to('cuda')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    for relation_index in range(len(batch_data)): #5 relations - birtdate, birthplace,deatdate, deathplace, office\n",
        "      question=keys[relation_index].clone()#.to('cuda')\n",
        "\n",
        "      # print(\"q,k,v sizes:\" ,question.size(), keys.size(), values.size())\n",
        "      output = model(question.unsqueeze(0), keys.unsqueeze(0), values.unsqueeze(0))\n",
        "      output=output.squeeze(0)\n",
        "      # print(\"output: \",output.size())\n",
        "\n",
        "      # print(\"Y: \", Y.size())\n",
        "      embedded_Y = model.B(values.clone())\n",
        "      # print(\"embedded_Y: \", embedded_values.size())\n",
        "\n",
        "      softmax_output = torch.inner(embedded_Y, output)\n",
        "      # print(\"softmax_output: \",softmax_output.size())\n",
        "\n",
        "      target_index=torch.tensor(relation_index)#.to('cuda')\n",
        "      # print(\"target_index: \",target_index.size())\n",
        "\n",
        "\n",
        "\n",
        "      # Predicted class as the highest prob in output\n",
        "      predicted = softmax_output.argmax(dim=0)\n",
        "\n",
        "      if target_index==predicted:\n",
        "        correct+=1\n",
        "      total+=1\n",
        "\n",
        "accuracy=correct/total\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ecGNHCNhTGxK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c0352eb-55ff-4ed2-a574-d6100d052989"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.7878787878787878\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Suggestion:** Once you have a model that has decent accuracy, you may want to save it to your Google Drive using ``torch.save()`` and load it when working on the next part of the assignment using ``torch.load()``."
      ],
      "metadata": {
        "id": "fSfTnmWbf0Pr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#saving best model\n",
        "path = F\"/content/drive/My Drive/kvmemnet_model.pth\"\n",
        "torch.save(model.state_dict(), path)"
      ],
      "metadata": {
        "id": "EELNYVfIVqkP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Load the model\n",
        "path = F\"/content/drive/My Drive/kvmemnet_model.pth\"\n",
        "model_reloaded = KVMemNet(vocab_size, embed_dim)\n",
        "model_reloaded.load_state_dict(torch.load(path))\n",
        "model_reloaded.eval()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BzxkqhNgT61x",
        "outputId": "1c5831b1-e076-4e95-d4d3-d39f4f3e8ddc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "KVMemNet(\n",
              "  (A): Linear(in_features=96093, out_features=100, bias=True)\n",
              "  (B): Linear(in_features=96093, out_features=100, bias=True)\n",
              "  (softmax): Softmax(dim=1)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lRCn-LZmMNCp"
      },
      "source": [
        "# Part E: Use the Model (5 points)\n",
        "\n",
        "Given a question in natural language, turn it into a bag of words and feed it into the model with a set of plausible keys and values. Apply the output feature embedding to the full set of values and pick the value with argmax. Return the actual text inside that value (not the bag of words or embedding).\n",
        "\n",
        "That is, given a natural language question, you are asked to create the $q$ and pick a relevant subset of $k$ and $v$. Run the $q$, $k$, and $v$ through the model and get an answer to the original question.\n",
        "\n",
        "For example a question might be \"When was Alexander Hamilton born?\" Depending on how you pre-proessed your data, you may need to extract the entity and the relation.\n",
        "\n",
        "Write a function that takes in the `question` below, the data, and the model, and outputs the text answer, e.g., \"11 january 1755\". You must use your ``KVMemNet``."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Suggestion:** To process a question you will probably want to find the entity and the relation. You may use packages such as [NLTK](https://www.nltk.org/) (already imported), [SpaCY](https://spacy.io/), [Stanza](https://stanfordnlp.github.io/stanza/), or other."
      ],
      "metadata": {
        "id": "yiRYRlRhfFUG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Change the question to test your implementation, but don't delete this cell."
      ],
      "metadata": {
        "id": "ofPVuNzWeIto"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JQLNvGsfm3b3"
      },
      "outputs": [],
      "source": [
        "question = \"When was alexander hamilton born?\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Create your function for using the `KVMemNet` to answer a given question.**\n",
        "\n",
        "The function should take in the question, data, model, and any other parameters you need. The function should return a text string.\n",
        "\n",
        "You can create as many cells as necessary. Save the notebook cells showing one example of your input question and output answer. For grading we will look to see that your question is in natural language, the model is used, and the answer is in text. The example doesn't have to be correct. You will analyze your technique later in the report."
      ],
      "metadata": {
        "id": "KGSewc7jeaj1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create your functions here\n",
        "\n",
        "'''\n",
        "Steps:\n",
        "- Given a natural language question, I am extracting the person-name (question) and verb (relation) using POS tags of NOUN and VERB resp.\n",
        "- To create the q and pick a relevant subset of  k  and  v, I am getting the batch where question has the target name person.\n",
        "- Pick the key corresponding to the question using similarity of the relation word (verb) from natural language question amongst the relevant subset of k for the person found in above step.\n",
        "- Run the  q ,  k , and  v  through the model and get an answer to the original question using the key-value-memory network model.\n",
        "- Return the actual text inside that value (not the bag of words or embedding).\n",
        "\n",
        "'''\n",
        "\n",
        "def getanswer(question, data=DB, model=model_reloaded):\n",
        "\n",
        "\n",
        "  #1. Extract the name and relation from question\n",
        "  import nltk\n",
        "  nltk.download('punkt_tab')\n",
        "  nltk.download('averaged_perceptron_tagger_eng')\n",
        "  nltk.download('maxent_ne_chunker_tab')\n",
        "  nltk.download('punkt')\n",
        "  nltk.download('maxent_ne_chunker')\n",
        "  nltk.download('words')\n",
        "  from nltk import word_tokenize, pos_tag, ne_chunk\n",
        "\n",
        "  words = word_tokenize(question)\n",
        "  # print(words)\n",
        "  tagged_words = pos_tag(words)\n",
        "  # print(tagged_words)\n",
        "  named_entities = ne_chunk(tagged_words)\n",
        "  # print(named_entities)\n",
        "\n",
        "  names = [word for word, tag in tagged_words if tag == 'NN']\n",
        "  names=names[-1]\n",
        "  relation = [word for word, tag in tagged_words if tag == 'VBN']\n",
        "  relation=relation[-1]\n",
        "  # print(\"Extracted Names,relation:\", names,relation)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  #2. Get the batch where question has the target name person\n",
        "  target_name= names #'alexander hamilton'\n",
        "\n",
        "  target_d=[]\n",
        "  for name, content in DB.items():\n",
        "    # print(name,\"-\",content)\n",
        "    if target_name in name:\n",
        "      person=[]\n",
        "      for key, value in content.items():\n",
        "        if \"birth\" in key or \"death\" in key or \"office\" in key:\n",
        "          # print(name, \"-\" , key, \"-\" , value)\n",
        "          tmp = [name, \"{} {}\".format(name, key), \"{} {}\".format(name, value)]\n",
        "          person.append(tmp)\n",
        "      target_d.append(person)\n",
        "\n",
        "  # print(target_d)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  #3. Get the key to query\n",
        "  import spacy\n",
        "  nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "  verb = [relation]\n",
        "  list_keys = [row[1] for row in target_d[0]]\n",
        "\n",
        "  most_similar_words = {}\n",
        "\n",
        "  for word1 in verb:\n",
        "      max_similarity = -1\n",
        "      most_similar_word = None\n",
        "      word1_vec = nlp(word1)\n",
        "\n",
        "      for word2 in list_keys:\n",
        "          word2_vec = nlp(word2)\n",
        "          similarity = word1_vec.similarity(word2_vec)\n",
        "\n",
        "          if similarity > max_similarity:\n",
        "              max_similarity = similarity\n",
        "              most_similar_word = word2\n",
        "\n",
        "      most_similar_words[word1] = most_similar_word\n",
        "\n",
        "  for word, similar in most_similar_words.items():\n",
        "      # print(f\"Most similar phrase to '{word}' is '{similar}'\")\n",
        "      target_relation =similar #'alexander hamilton birth_date'\n",
        "\n",
        "\n",
        "\n",
        "  #4. Get corresponding value to the target_relation and name\n",
        "  batch_data = target_d[0]\n",
        "  # print(\"batch_data shape: \", batch_data)\n",
        "  keys=[multihot(row[1], VOCAB) for row in batch_data]\n",
        "  values=[multihot(row[2], VOCAB) for row in batch_data]\n",
        "  keys=torch.tensor(keys)#.to('cuda')\n",
        "  values=torch.tensor(values)#.to('cuda')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  question=target_relation#.to('cuda')\n",
        "  question=[multihot(question, VOCAB)]\n",
        "  question=torch.tensor(question)#.to('cuda')\n",
        "\n",
        "  # print(\"q,k,v sizes:\" ,question.size(), keys.size(), values.size())\n",
        "  output = model_reloaded(question, keys.unsqueeze(0), values.unsqueeze(0))\n",
        "  output=output.squeeze(0)\n",
        "  # print(\"output: \",output.size())\n",
        "\n",
        "  # print(\"Y: \", Y.size())\n",
        "  embedded_Y = model.B(values.clone())\n",
        "  # print(\"embedded_Y: \", embedded_values.size())\n",
        "\n",
        "  softmax_output = torch.inner(embedded_Y, output)\n",
        "  # print(\"softmax_output: \",softmax_output.size())\n",
        "\n",
        "\n",
        "  # Predicted class as the highest prob in output\n",
        "  predicted = softmax_output.argmax(dim=0)\n",
        "\n",
        "  predicted_text = batch_data[predicted][2]\n",
        "\n",
        "  # print(f\"Predicted: {predicted}\")\n",
        "  # print(f\"Predicted Text: {predicted_text}\")\n",
        "  return predicted_text"
      ],
      "metadata": {
        "id": "sN0ZNtADTzDd"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DB['alexander hamilton']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XDxvPMTnpL9m",
        "outputId": "ce4e0a1a-51f0-4157-a99d-52f824b5920f"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'name': 'alexander hamilton',\n",
              " 'office': '1st united states secretary of the treasury senior officer of the army delegate to the congress of the confederation from new york',\n",
              " 'president': 'george washington john adams',\n",
              " 'term_start': 'september 11 1789 december 14 1799 november 3 1788 november 4 1782',\n",
              " 'term_end': 'january 31 1795 june 15 1800 march 2 1789 june 21 1783',\n",
              " 'predecessor': 'position established george washington egbert benson seat established',\n",
              " 'successor': 'oliver wolcott jr james wilkinson seat abolished seat abolished',\n",
              " 'birth_date': '11 january 1755',\n",
              " 'birth_place': 'charlestown nevis british west indies',\n",
              " 'death_date': 'july 12 1804 aged 47 or 49',\n",
              " 'death_place': 'new york city new york u',\n",
              " 'party': 'federalist',\n",
              " 'spouse': 'elizabeth schuyler',\n",
              " 'children': 'philip angelica alexander james alexander john church william stephen eliza holly phil',\n",
              " 'alma_mater': 'kings college new york',\n",
              " 'religion': 'presbyterian episcopalian convert',\n",
              " 'signature': 'alexander hamilton signaturert',\n",
              " 'allegiance': 'flag_of_new_york _ 1778 svg 23px new york 1775 1777 united states 1795 23px 1777 1800',\n",
              " 'branch': 'flag_of_new_york _ 1778 svg 23px new york company of artillery united states 1777 23px continental army 25px united states army',\n",
              " 'serviceyears': '1775 1776 militia 1776 1781 1798 1800',\n",
              " 'rank': '23px',\n",
              " 'article_title': 'alexander hamilton'}"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "DB['alexander hamilton mcdonald']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eoB8YZcPQbyS",
        "outputId": "9503e430-3055-45bf-ff50-48475bd08d65"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'name': 'alexander hamilton mcdonald',\n",
              " 'office': 'senator from saskatchewan moosomin leader of the opposition saskatchewan mla for moosomin',\n",
              " 'term_start': '1965 1955 1952',\n",
              " 'term_end': '1980 1960 1965',\n",
              " 'predecessor': 'asmundur a loptson arthur thomas procter',\n",
              " 'successor': 'ross thatcher frank gardner',\n",
              " 'birth_date': 'march 16 1919',\n",
              " 'birth_place': 'fleming saskatchewan',\n",
              " 'death_date': 'march 31 1980',\n",
              " 'death_place': 'ottawa',\n",
              " 'party': 'saskatchewan liberal party',\n",
              " 'otherparty': 'liberal party of canada',\n",
              " 'spouse': 'madeleine anne casey',\n",
              " 'religion': 'united church of canada',\n",
              " 'article_title': 'alexander hamilton mcdonald'}"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"When was alexander hamilton born?\"\n",
        "predicted_ans=getanswer(question)\n",
        "print(\"Question: \", question)\n",
        "print(\"Answer predicted: \", predicted_ans)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L7MYLNtkWBKq",
        "outputId": "98523c13-5102-4df9-de12-a6091cdcc020"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package maxent_ne_chunker_tab to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package maxent_ne_chunker_tab is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package maxent_ne_chunker to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Package words is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question:  When was alexander hamilton born?\n",
            "Answer predicted:  alexander hamilton mcdonald march 16 1919\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"When was alexander hamilton dead?\"\n",
        "predicted_ans=getanswer(question)\n",
        "print(\"Question: \", question)\n",
        "print(\"Answer predicted: \", predicted_ans)\n",
        "\n",
        "'''\n",
        "Analysis:\n",
        "I used spaCy to identify the most relevant key (relation) among the five predefined relations based on semantic similarity to the relation word in the natural language question. But the model incorrectly mapped the word 'dead' to 'birth date' instead of 'death date', due to the similarity limitations—resulting in the answer being incorrectly linked to the birth date rather than the intended death-date related information.\n",
        "\n",
        "Another limitation of my approach is that it doesn't account for question words like 'What', 'When', or 'Who', which provide important context for interpreting the relation. So when the question contains 'When', it should ideally guide the model toward time-related keys like birth date or death date. However, since my current method only matches based on the verb—like 'dead'—and not the full intent of the question, it may incorrectly map 'When' to place-related keys (e.g., birth-place or death-place) instead of date-related ones, leading to inaccurate answer selection from the available relations: birth-place, birth-date, death-place, death-date, and office.\n",
        "\n",
        "Another limitation of my approach is in identifying the correct person from the DB. For example, if the question is about 'alexander hamilton', but the database contains an entry for 'alexander hamilton mcdonald', the system might incorrectly match the longer name simply because it contains the queried noun. Since my current logic extracts the person name from the natural language input and looks for a match in the database based on noun phrases, it can lead to partial or fuzzy matches that aren't contextually accurate and thus resulting in the answer being returned for the wrong person.\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C0yZfgA8Nc6D",
        "outputId": "ddbc58cb-49bc-442d-b536-ae0f38ca3008"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package maxent_ne_chunker_tab to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package maxent_ne_chunker_tab is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package maxent_ne_chunker to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Package words is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracted Names,relation: hamilton dead\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-40-5433484bfb4f>:88: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
            "  similarity = word1_vec.similarity(word2_vec)\n",
            "<ipython-input-40-5433484bfb4f>:107: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /pytorch/torch/csrc/utils/tensor_new.cpp:254.)\n",
            "  keys=torch.tensor(keys)#.to('cuda')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question:  When was alexander hamilton dead?\n",
            "Answer predicted:  alexander hamilton mcdonald march 16 1919\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"What was alexander hamilton office?\"\n",
        "predicted_ans=getanswer(question)\n",
        "print(\"Question: \", question)\n",
        "print(\"Answer predicted: \", predicted_ans)\n",
        "\n",
        "'''\n",
        "Analysis:\n",
        "Although here also wrong person identified based on POS noun 'alexander' available in the DB, but the context of 'office' was able to be mapped to the key properly and thus the relevant value retrieved as answer.\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uzod2ZpuWeZI",
        "outputId": "74dc4a5b-c07c-444d-f919-f5fefb59db58"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package maxent_ne_chunker_tab to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package maxent_ne_chunker_tab is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package maxent_ne_chunker to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Package words is already up-to-date!\n",
            "<ipython-input-53-55ea5dd60b1e>:88: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
            "  similarity = word1_vec.similarity(word2_vec)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question:  What was alexander hamilton office?\n",
            "Answer predicted:  alexander hamilton mcdonald senator from saskatchewan moosomin leader of the opposition saskatchewan mla for moosomin\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "DB['maurice delory']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wvm0eQyBVHXG",
        "outputId": "9ce274fb-3b89-4edd-bf07-29ce5c594a01"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'name': 'maurice delory',\n",
              " 'birth_date': '5 october 1927',\n",
              " 'birth_place': 'georgetown prince edward island',\n",
              " 'office': 'mla for lunenburg west',\n",
              " 'term_start': '1970',\n",
              " 'term_end': '1978',\n",
              " 'predecessor': 'harley j spence',\n",
              " 'successor': 'mel pickings',\n",
              " 'party': 'liberal',\n",
              " 'religion': 'roman catholic',\n",
              " 'occupation': 'lawyer',\n",
              " 'article_title': 'maurice delory'}"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"When was maurice delory born?\"\n",
        "predicted_ans=getanswer(question)\n",
        "print(\"Question: \", question)\n",
        "print(\"Answer predicted: \", predicted_ans)\n",
        "\n",
        "'''\n",
        "Analysis:\n",
        "'maurice delory' was not recognized as a noun/ proper noun hence my function could not pick it as the person and thus no person data was able to be picked from the DB. Will need more exhaustive way of picking the person in context from the natural language question.\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 627
        },
        "id": "6I3gjBJrVU5Q",
        "outputId": "1aa87776-81e6-4c03-bb61-1d675dbe53ed"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package maxent_ne_chunker_tab to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package maxent_ne_chunker_tab is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package maxent_ne_chunker to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Package words is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('When', 'WRB'), ('was', 'VBD'), ('maurice', 'RB'), ('delory', 'JJ'), ('born', 'VBN'), ('?', '.')]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "list index out of range",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-49-3872b531d2ab>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mquestion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"When was maurice delory born?\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpredicted_ans\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgetanswer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquestion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Question: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquestion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Answer predicted: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted_ans\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-47-f770adb75fa6>\u001b[0m in \u001b[0;36mgetanswer\u001b[0;34m(question, data, model)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m   \u001b[0mnames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtag\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtagged_words\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtag\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'NN'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m   \u001b[0mnames\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m   \u001b[0mrelation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtag\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtagged_words\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtag\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'VBN'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m   \u001b[0mrelation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrelation\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: list index out of range"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part F: Reporting (15 points)\n",
        "\n",
        "Your report should answer the following three questions:\n",
        "\n",
        " **Q1:** What pre-processing of the data did you do? What motivated the design decisions and how did it impact training and any processing of natural language questions (Parts A and D)?\n",
        "\n",
        " Hint: This should help one understand any code modifications you made in Parts A and the first part of Part D. But you shouldn't use this to document your code (hopefully you commented your code with code comments and text cells above), but to justify your choices as well as to explain what worked and what didn't work.\n",
        "\n",
        " **Q2:** Report on your training on the real data (Part D). Show your loss curve and report on the testing accuracy. There are many ways to implement the training loop, particularly with the choice of keys and values. What decisions did you make when developing your training loop? Justify your decisions. How did they impact the training?\n",
        "\n",
        " Hint: This assignment doesn't grade you on how well your model learns---your solution will not be perfect. We focus more on how you worked through the process. This part of the report should show how well your solution worked, but also the intuition for why it works, and to document the things you tried that didn't work.\n",
        "\n",
        " **Q3:** Describe your technique on how you process natural language questions (Part E). Provide some examples of your technique answering questions correctly and some examples of your technique answering questions incorrectly. Discuss what causes the failure cases.\n",
        "\n",
        " Hint: You are not penalized for incorrectly answered questions---your model will not be perfect---we are looking for honest reflection. Preferably, show the example as code blocks running your model with notebook outputs saved.\n",
        "\n",
        " We have provided three prompts below. You can create as many text and code cells as necessary."
      ],
      "metadata": {
        "id": "N27-OtrzpT-u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q1: Report on Data Pre-processing**"
      ],
      "metadata": {
        "id": "V8dovCuyuEvL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- For the pre-processing of data I went ahead with the naive approach demonstrated in the recitation, to treat a question as the name of a person and a relation, for example: \"Alexander Hamilton birth date\". The question as extracted from natural language may contain information about the person and some words that are representative of the relation even if the exact relation words aren't used as per the q,k,v set.\n",
        "\n",
        "- For each person, I extracted only a subset of relation types: birth date, birth place, death date, death place, and office to work with the limited computation with CPU allowed in my Colab subscription. Each training row corresponds to a specific person, and within that, each row represents a particular relation associated with that person. The key design decision was in how I structured the (q, k, v) triplets-\n",
        "  - q = name of the person\n",
        "  - k = key representation (name + relation type like \"Alexander Hamilton birth date\")\n",
        "  - v = the corresponding value (name + relation type like \"Alexander Hamilton 11 january 1755\")\n",
        "\n",
        "  This training set orchestration ensured that training was focused within a person specific BOW context, rather than performing a search across the entire knowledge base. This choice was motivated by the need to reduce the search space, improve training efficiency, and make it computationally feasible. I am working with CPU hence just trained with 100 person records to further use computation in an optimised way but not to an extent that overfitting occurs.\n",
        "\n",
        "- For setting Y during training here in case of the original training DB, unlike the synthetic data, The recitation showed we are attempting to figure out in the person specific BOW only rather than all the values in the database (which helped with computation limitations to use only CPU). In case GPU was available, I could have overcome this by trying to fetch the answer/ value from a more general pool of values/ BOW. I could have also trained with more number of training person (>100 person trainset only) to provide more context to the model.\n",
        "\n",
        "- For the KVMemNet model creation I had set a larger embedding size than synthetic data because the vocab size is huge here, so while squeezing all info from vocab_size to the embedding_size less info loss would be faced and the output weights would have better context of the person and relation.\n"
      ],
      "metadata": {
        "id": "2qhr3QwvuLBQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q2: Report on Training and Testing**"
      ],
      "metadata": {
        "id": "3VBW1vSduN4U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Your text here."
      ],
      "metadata": {
        "id": "PT_9MtT2uQ7I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q3: Report on Model Use**"
      ],
      "metadata": {
        "id": "d6YimJ0KuScb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Your text here."
      ],
      "metadata": {
        "id": "j1majVIPuVEP"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "XLQP14bxNXDx",
        "Sl6J8BwVpHCw",
        "p8pshjz9hRps",
        "G6R_xIi_TZVp"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}